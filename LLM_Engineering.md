1. We are using “UV” instead of conda environment. UV  is built using rust and it is much faster can conda.

2. Use the following version of OpenAI - 2.7.2

3. There are two types of prompt - 
    1. { ‘role’ : “system”, “content”:”system message goes here”}
    2. {‘role’ : “user”, “content”:”hi how are you?”}

4. Assignment - Scrape a website and summarise it using openAI

5. LLMs are also known as “Frontier Models”. Frontier models are closed source models and we need to pay to use them. Following are few of the Frontier models - GPT from OpenAI, Claude from Anthropic, Gemini from Google, Grok from X.ai

6. Open Source Models - Llama from Meta, Mixtral from Mistral, Qwen from Alibaba cloud, Gemma from Google, Phi from Microsoft, DeepSeek from DeepSeekAI, GPT-OSS from OpenAI

7. Three different ways to used the models -
    1. Chat interfaces like ChatGPT
    2. Cloud APIs ( LLM API, Frameworks like LangChain, Managed AI cloud services like AWS BedRock, Google Vertex, Azure ML )
    3. Direct Interface. Using HuggingFace & Transformers library with Ollama to run locally.
    4. There is a different model called “Groq”. This is different than Elon musk’s grok

8. Transformers - 2017, Google researchers wrote a paper named “Attention is all you need” proposing a new architecture called Transformers. 





